
I am a researcher working on multi-sensor stochastic methods for robotic semantic perception. My current work focuses on learning sensorimotor representations for scene understanding through the interaction of perception and action processes. I am interested on proposing and developing intelligent systems and robotic platforms that interact with the real world.

## <a name="currentresearch"></a> Current research

We study the traversability problem for mobile robotics. For example, ground robots operating on unstructured terrain must predict which areas of the environment they are able to pass in order to plan feasible paths.
We address traversability estimation for ground robots as a heightmap classification problem: we build a convolutional neural network that, given an image representing the heightmap of a terrain patch, predicts whether the robot will be able to traverse such patch from left to right.

The classifier is trained for a specific wheeled robot model using simulation data on procedurally generated training terrains; the trained classifier can be applied to unseen large heightmaps to yield oriented traversability maps, and then plan traversable paths.
We extensively evaluate the approach in simulation on real-world elevation datasets, and run a real-robot validation for indoor and outdoor environments. Data and code to reproduce the results and media material can be found at [github](http://romarcg.xyz/traversability_estimation/).

*Related videos:*

{% include vimeoPlayer.html id=247479519 width=320 height=270 %}

{% include vimeoPlayer.html id=247478850 width=320 height=270 %}

{% include vimeoPlayer.html id=224311774 width=320 height=270 %}

{% include vimeoPlayer.html id=224311892 width=320 height=270 %}

&nbsp;

[The National Centre of Competence in Research (NCCR) Robotics](https://www.nccr-robotics.ch/)

&nbsp;

## <a name="previousresearch"></a> Previous research

### Discovering and Manipulating Affordances

We studied and developed sensori­motor representations that fuse perceptual data (scene and parts of the agent), proprioceptive feedback (agent’s own configuration), contextual information (previous knowledge) and the agent’s goals. We shall develop theories about the importance and influence of each input and their fusion for understanding the scene.

We assumed that scene interpretation is necessarily related to learning new objects or adding knowledge about known  objects. Hence we shall also study the relationship between interpretation and learning.
The learning process will consist in building sensorimotor representations of both scene elements and associated actions.

[RoboErgoSum - Self Aware Robots](http://roboergosum.isir.upmc.fr/), was a four year project funded by the French National Research Agency ANR which objective is to explore artificial conscienceness in robotics.

[The Institute for Intelligent Systems and Robotics (ISIR)](http://www.isir.upmc.fr/) <br/>
[University Pierre et Marie Curie](http://www.upmc.fr/en/) <br/>
[The National Center for Scientific Research](http://www.cnrs.fr/)


### Multiple Sensor Fusion and Classification for Moving Object Detection and Tracking

I worked on probabilistic and credibilist methods to fuse information from a heterogeneous array of sensors.
Three modules were proposed and implemented to work simultaneously in an Advance Driver Assistant System: multi-target object detection, classification and tracking of multiple objects in dynamic scenarios.

In the framework of *perception* inside [interactIVe](http://www.interactive-ip.eu/) (accident avoidance by active intervention for Intelligent Vehicles) IP European Project I proposed and developed a multi-sensor fusion solution software for a frontal object perception application. It involved: outdoor environment mapping; detection, tracking and classification of multiple objects of interest in different driving scenarios. Multiple sensors (lidar, camera and radar) fusion was at the core of the perception task.
The solution was part of a whole automotive application involving several car manufacturers and suppliers inside *interactIVe* project.

*Related videos:*

{% include youtubePlayer.html id="tRdZBzfSMzk" %}

{% include youtubePlayer.html id="UZdwP-Z9mkA" %}

[Grenoble Informatics Laboratory](https://www.liglab.fr/en) <br/>
[Université Grenoble Alpes](http://www.univ-grenoble-alpes.fr/)

## <a name="publications"></a> Publications

<bibtex src="/docs/library.bib"></bibtex>

<div class="bibtex_template">
  <span class="title"></span>.
  <span class="author"></span>.
  <span class="if journal">
    <span class="journal"></span>,
    <span class="if volume"> vol.
      <span class="volume"></span>,
    </span>
    <span class="if issue"> issue
      <span class="issue"></span>,
    </span>
  </span>
  <span class="if booktitle">
    <span class="booktitle"></span>,
  </span>
  <span class="if pages">pp.
    <span class="pages"></span>,
  </span>
  <span class="if year">
    <span class="year"></span>.
  </span>
  <span class="if url">
    <a class="url">(view online)</a>
  </span>
</div>

<div id="bibtex_display"></div>

&nbsp;

## <a name="cv"></a> Curriculum vitae

A pdf version is found [here](/docs/cv.pdf)

&nbsp;

## <a name="contact"></a> Contact

>*Dalle Molle Institute for Artificial Intelligence Research (IDSIA)* <br/>
>*University of Applied Sciences and Arts of Southern Switzerland (SUPSI)<br/>*
>*Università della Svizzera italiana* <br/>
> *Galleria 2, Via Cantonale 2c* <br/>
> *CH-6928 Manno* <br/>
> *Switzerland* <br/>
> omar ![arr](images/icon-at-s.png "arr") idsia ![arr](images/icon-point-s.png "poi") ch <br/>


[linkedin]: https://fr.linkedin.com/in/ricardo-omar-chavez-garcia-029b5734 "My profile in LinkedIn"
[rg]: https://www.researchgate.net/profile/Ricardo_Chavez-Garcia "My profile in ResearchGate"

> [LinkedIn][linkedin] &nbsp; [Research Gate][rg] <br/>

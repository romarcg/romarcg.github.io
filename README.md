
I am a researcher working on multi-sensor stochastic methods for robotic semantic perception. My current work focus on learning sensorimotor representations for scene understanding through the interaction of perception and action processes. I am interested on proposing and developing intelligent systems and robotic platforms that interact with the real world.

## <a name="currentresearch"></a> Current research

Mobile ground robots operating on unstructured terrain must predict which areas of the environment they are able to pass in order to plan feasible paths.
We address traversability estimation as a heightmap classification problem: we build a convolutional neural network that, given an image representing the heightmap of a terrain patch, predicts whether the robot will be able to traverse such patch from left to right.

The classifier is trained for a specific robot model (wheeled, tracked, legged, snake-like) using simulation data on procedurally generated training terrains; the trained classifier can be applied to unseen large heightmaps to yield oriented traversability maps, and then plan traversable paths. We extensively evaluate the approach in simulation on six real-world elevation datasets, and run a real-robot validation in one indoor and one outdoor environment.




## <a name="previousresearch"></a> Previous research

### Discovering and Manipulating Affordances

We studied and developed sensori­motor representations that fuse perceptual data (scene and parts of the agent), proprioceptive feedback (agent’s own configuration), contextual information (previous knowledge) and the agent’s goals. We shall develop theories about the importance and influence of each input and their fusion for understanding the scene.

We assumed that scene interpretation is necessarily related to learning new objects or adding knowledge about known  objects. Hence we shall also study the relationship between interpretation and learning.
The learning process will consist in building sensorimotor representations of both scene elements and associated actions.

[RoboErgoSum - Self Aware Robots](http://roboergosum.isir.upmc.fr/), was a four year project funded by the French National Research Agency ANR which objective is to explore artificial conscienceness in robotics.

[The Institute for Intelligent Systems and Robotics (ISIR)](http://www.isir.upmc.fr/) <br/>
[University Pierre et Marie Curie](http://www.upmc.fr/en/) <br/>
[The National Center for Scientific Research](http://www.cnrs.fr/)

[&uarr;](#toppage)

### Multiple Sensor Fusion and Classification for Moving Object Detection and Tracking

I worked on probabilistic and credibilist methods to fuse information from an heterogeneous array of sensors.
Three modules were proposed and implemented to work simultaneously in a and Advance Driver Assistant System: multi-target object dectection, classification and tracking of multiple objects in dynamic scenarios.

[//]: <> (>*### Responsible of the Perception sub-project - interactIVe (accident avoidance by active intervention for Intelligent Vehicles) IP European Project*)

In the framework of the Perception inside [interactIVe](http://www.interactive-ip.eu/) (accident avoidance by active intervention for Intelligent Vehicles) IP European Project I proposed and developed a multi-sensor fusion solution software for a frontal object perception application. It involved: outdoor environment mapping; detection, tracking and classification of multiple objects of interest in different driving scenarios. Multiple sensor (lidar, camera and radar) fusion was at the core of the perception task.
The solution was part of a whole automotive application involving several car manufacturers and suppliers inside *interactIVe* project.

*Related videos:*

<iframe id="ytplayer" type="text/html" width="320" height="270" src="http://www.youtube.com/embed/tRdZBzfSMzk?autoplay=0&origin=http://www.romarcg.xyz"  frameborder="0"> </iframe>

<iframe id="ytplayer" type="text/html" width="320" height="270" src="http://www.youtube.com/embed/UZdwP-Z9mkA?autoplay=0&origin=http://www.romarcg.xyz"  frameborder="0"> </iframe>

[Grenoble Informatics Laboratory](https://www.liglab.fr/en) <br/>
[Université Grenoble Alpes](http://www.univ-grenoble-alpes.fr/)

[&uarr;](#toppage)

## <a name="publications"></a> Publications

<bibtex src="/docs/library.bib"></bibtex>

<div class="bibtex_template">
  <span class="title"></span>.
  <span class="author"></span>.
  <span class="if journal">
    <span class="journal"></span>,
    <span class="if volume"> vol.
      <span class="volume"></span>,
    </span>
    <span class="if issue"> issue
      <span class="issue"></span>,
    </span>
  </span>
  <span class="if booktitle">
    <span class="booktitle"></span>,
  </span>
  <span class="if pages">pp.
    <span class="pages"></span>,
  </span>
  <span class="if year">
    <span class="year"></span>.
  </span>
  <span class="if url">
    <a class="url">(view online)</a>
  </span>
</div>

<div id="bibtex_display"></div>

[&uarr;](#toppage)

## <a name="cv"></a> Curriculum vitae

A pdf version is found [here](/docs/cv.pdf)

[&uarr;](#toppage)



## <a name="contact"></a> Contact

[//]: <> (>*Institut des Systèmes Intelligents et de Robotique (ISIR)* <br/>)

[//]: <> (>*Université Pierre et Marie CURIE* <br/>)

[//]: <> (> *Pyramide - T55/65* <br/>)

[//]: <> (> *CC 173 - 4 Place Jussieu* <br/>)

[//]: <> (> *75005 Paris* <br/>)

[//]: <> (> chavez <i class="icon-at"></i> isir <i class="icon-point"></i> upmc <i class="icon-point"></i> fr <br/>)

>*Dalle Molle Institute for Artificial Intelligence Research (IDSIA)* <br/>
>*University of Applied Sciences and Arts of Southern Switzerland (SUPSI)<br/>*
>*Università della Svizzera italiana* <br/>
> *Galleria 2, Via Cantonale 2c* <br/>
> *CH-6928 Manno* <br/>
> *Switzerland* <br/>
> omar ![arr](images/icon-at-s.png "arr") idsia ![arr](images/icon-point-s.png "poi") ch <br/>

[//]: <> (>*Scuola Universitaria Professionale della Svizzera Italiana<br/>*)

[linkedin]: https://fr.linkedin.com/in/ricardo-omar-chavez-garcia-029b5734 "My profile in LinkedIn"
[rg]: https://www.researchgate.net/profile/Ricardo_Chavez-Garcia "My profile in ResearchGate"

> [LinkedIn][linkedin] &nbsp; [Research Gate][rg] <br/>


[&uarr;](#toppage)
